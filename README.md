# Voice Memo Sentiment & Insights Pipeline (DeAlexithyminator - *Demystify Your Emotions*)  

### **Automated voice memo processing with Whisper, NLP sentiment analysis, and cloud storage sync across Google Cloud & iCloud.**  

Originally a project to combat the troubles of exploring mindfulness with journaling in a hyper-focused, fast-paced, and constantly changing world, This project allows users, with a tap of an icon, **to record a voice memo on their phone, automatically upload it to Google Cloud Storage, transcribe it using OpenAI's Whisper, analyze sentiment, and generate critical but gentle insights with ChatGPT**. The results are saved as text files in **Google Cloud Storage and iCloud**, made as intuitively possible by Apple's Shortcut app making them instantly accessible across devices.  

---

## **âœ¨ Features**
âœ… **Automated Voice Memo Processing** â€“ Upload voice memos from mobile to Google Cloud automatically.  
âœ… **Whisper Transcription** â€“ Converts speech to text with OpenAI's Whisper.  
âœ… **Sentiment Analysis** â€“ Uses TextBlob to analyze the emotional tone of the transcript.  
âœ… **ChatGPT Insights** â€“ Generates deeper reflections based on the transcription.  
âœ… **Google Cloud Storage Sync** â€“ Stores input/output files in cloud storage for accessibility.  
âœ… **iCloud Sync** â€“ Stores processed results in iCloud for quick access from mobile.  
âœ… **Local Watch Folder** â€“ Supports local-to-cloud syncing using symlinks.  

---

## **ğŸ› ï¸ How It Works**
ğŸ“± **1. Record a Voice Memo** â†’ Uploads automatically via iCloud Shortcuts to the **TranscriptionInbox** folder.  
ğŸ“¤ **2. File Syncs to Google Cloud Storage** â†’ A local watcher uploads new files to the **voice-memo-inputs** bucket.  
ğŸ™ï¸ **3. Transcription & Processing** â†’ The script:  
   - Converts M4A files to MP3 (if needed).  
   - Uses Whisper to transcribe the audio.  
   - Runs sentiment analysis & generates ChatGPT insights.  
ğŸ“„ **4. Stores Results** â†’ Saves transcriptions & analysis in Google Cloud and iCloud for easy access.  

---

## **ğŸ› ï¸ Tech Stack**
- **Python 3.12**  
- **Google Cloud Storage (GCS)**  
- **OpenAI Whisper**  
- **TextBlob (Sentiment Analysis)**  
- **ChatGPT API (Insights Generation)**  
- **FFmpeg (Audio Conversion)**  
- **Librosa (Audio Feature Extraction)**  

---

## **ğŸš€ Setup & Installation**

### **1ï¸âƒ£ Clone the Repo**
```sh
git clone https://github.com/YOUR_USERNAME/voice-memo-pipeline.git
cd voice-memo-pipeline
```

### **2ï¸âƒ£ Install Dependencies**
```sh
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up Google Cloud**
Create two GCS Buckets:

voice-memo-inputs (for uploaded voice memos)
voice-memo-outputs (for processed transcriptions)
Create a Service Account, download the JSON key, and authenticate:

```sh
gcloud auth activate-service-account --key-file=your-key.json
Enable required APIs:
```

```sh
gcloud services enable storage.googleapis.com
```

### **4ï¸âƒ£ Configure Your JSON Settings**
Modify config.json with your own bucket names, folder paths, and API keys:
```sh
{
    "input_bucket_name": "voice-memo-inputs",
    "output_bucket_name": "voice-memo-outputs",
    "inbox_folder": "TranscriptionInbox/",
    "processed_folder": "ProcessedTransAudio/",
    "icloud_folder": "~/Library/Mobile Documents/com~apple~CloudDocs/ProcessedTransAudio",
    "local_watch_folder": "~/Library/Mobile Documents/com~apple~CloudDocs/TranscriptionInbox",
    "poll_interval": 30,
    "openai_api_key": "your-openai-api-key"
}
```

### **5ï¸âƒ£ Set Up iCloud Sync**
Create a symlink from iCloud's TranscriptionInbox to your project:

```sh
ln -s ~/Library/Mobile\ Documents/com~apple~CloudDocs/TranscriptionInbox ~/voice-memo-pipeline/data/inbox
```

### **ğŸ“ Usage Guide**
After 1-5, Run pipeline
```sh
python transcribe-sentiment.py
```
The script watches your iCloud & GCS folders.
When a new voice memo appears, it uploads â†’ processes â†’ saves insights automatically.

#### **Test with a Sample File**
- Drop a voice memo (or a .m4a file) into your iCloud TranscriptionInbox folder.
- Watch it sync to Google Cloud & get processed.
- Check iCloud & GCS for results (ProcessedTransAudio).

### **ğŸ› ï¸ Debugging & Logs**
If files donâ€™t upload, check:

```sh
gcloud storage ls gs://voice-memo-inputs
```
If processing fails, inspect logs:

```sh
tail -f transcribe-sentiment.log
```

### **ğŸš€ Future Enhancements**
ğŸ”¹ Add Speaker Diarization â€“ Identify different speakers in a conversation.
ğŸ”¹ Improve Sentiment Analysis â€“ Use a fine-tuned BERT model for better accuracy.
ğŸ”¹ Event-Based Processing â€“ Replace polling with Cloud Pub/Sub triggers.
ğŸ”¹ Mobile App Integration â€“ Build a lightweight app UI for memo tracking.

### **ğŸ‘¤ Author**
Built by [@jeimcg](https://github.com/jeimcg) ğŸ› ï¸
Connect with me on [LinkedIn](https://www.linkedin.com/in/jares-mcgill-71676222a/) ğŸš€

### **ğŸ“œ License**
This project is licensed under the MIT License.
